
# PsychoPy Behavioral Tasks – Counterfactual & Social Risk Learning based on Barakchian et al. (2022) and Suzuki et al. (2016)

The experiments replicate key paradigms from two neuroscience papers:
* **Barakchian et al. (2022)** — contextual effects and *Opposing Learning* in partial vs. complete feedback RL. 
* **Suzuki et al. (2016)** — contagion of risk-preference via observation; neural encoding of risk. 

With focusing on:
- **Reinforcement learning under partial vs. complete feedback**
- **Social influence on risk preference (behavioral contagion)**

All tasks were developed in **PsychoPy Builder** (`.psyexp`) and can be run directly.


## 📂 Repository Structure

### 1️⃣ Barakchian — Counterfactual Learning in RL  
Based on: *Implicit Counterfactual Effect in Partial Feedback Reinforcement Learning* (Frontiers in Neuroscience, 2022)

```

Barakchian/
├── partial_feedback.psyexp
├── complete_feedback.psyexp
├── complete_feedback_lastrun.py   # Auto-generated by PsychoPy
└── Implicit-Counterfactual-Effect...pdf (reference paper)

```

🧠 Goal: Compare value learning when:
- Only **factual** outcomes are shown (Partial Feedback)
- Both **factual + counterfactual** outcomes are shown (Complete Feedback)

---

### 2️⃣ Suzuki — Social Risk Contagion  
Based on: *Behavioral Contagion During Risk-Preference Learning* (PNAS, 2016)

```

Suzuki/
├── sess_1.psyexp               # Baseline self-decisions
├── sess_2_risk_averse.psyexp   # Observing risk-averse agent
├── sess_3.psyexp               # Post-exposure decision session
├── sess_4_risk_seeking.psyexp  # Observing risk-seeking agent
├── sess_5.psyexp               # Final self-decision session
└── suzuki2016.pdf              # Reference paper

```

🧠 Goal: Track shifts in participant risk-taking after observing others’ decisions

---

## ▶️ How to Run

### Option A — Run in Coder (Recommended)
1. Install PsychoPy (≥ v2023.x)
2. Open `.psyexp` file in Builder  
3. Press **▶ Run**

Each session logs:
```

data/
├── subjectID_date.csv   # Choice, RT & reward logs

```

---

## 🔍 What is logged?

| Measure | Barakchian | Suzuki |
|--------|:---------:|:------:|
| Choices | ✅ | ✅ |
| Reaction Times | ✅ | ✅ |
| Reward Outcomes | ✅ | ✅ |
| Feedback Type | ✅ | ❌ |
| Social Context | ❌ | ✅ |

These logs are suitable for further **RL model fitting** (e.g., Q-learning & OL models).

---

## 📌 References

- Barakchian, Z. et al. (2022). *Implicit Counterfactual Effect in Partial Feedback Reinforcement Learning: Behavioral and Modeling Approach*. Frontiers in Neuroscience.  
- Suzuki, S. et al. (2016). *Behavioral Contagion During Learning About Another Agent’s Risk-Preferences*. PNAS.




