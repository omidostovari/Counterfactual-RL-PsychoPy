
# PsychoPy Behavioral Tasks â€“ Counterfactual & Social Risk Learning based on Barakchian et al. (2022) and Suzuki et al. (2016)

The experiments replicate key paradigms from two neuroscience papers:
* **Barakchian et al. (2022)** â€” contextual effects and *Opposing Learning* in partial vs. complete feedback RL. 
* **Suzuki et al. (2016)** â€” contagion of risk-preference via observation; neural encoding of risk. 

With focusing on:
- **Reinforcement learning under partial vs. complete feedback**
- **Social influence on risk preference (behavioral contagion)**

All tasks were developed in **PsychoPy Builder** (`.psyexp`) and can be run directly.


## ğŸ“‚ Repository Structure

### 1ï¸âƒ£ Barakchian â€” Counterfactual Learning in RL  
Based on: *Implicit Counterfactual Effect in Partial Feedback Reinforcement Learning* (Frontiers in Neuroscience, 2022)

```

Barakchian/
â”œâ”€â”€ partial_feedback.psyexp
â”œâ”€â”€ complete_feedback.psyexp
â”œâ”€â”€ complete_feedback_lastrun.py   # Auto-generated by PsychoPy
â””â”€â”€ Implicit-Counterfactual-Effect...pdf (reference paper)

```

ğŸ§  Goal: Compare value learning when:
- Only **factual** outcomes are shown (Partial Feedback)
- Both **factual + counterfactual** outcomes are shown (Complete Feedback)

---

### 2ï¸âƒ£ Suzuki â€” Social Risk Contagion  
Based on: *Behavioral Contagion During Risk-Preference Learning* (PNAS, 2016)

```

Suzuki/
â”œâ”€â”€ sess_1.psyexp               # Baseline self-decisions
â”œâ”€â”€ sess_2_risk_averse.psyexp   # Observing risk-averse agent
â”œâ”€â”€ sess_3.psyexp               # Post-exposure decision session
â”œâ”€â”€ sess_4_risk_seeking.psyexp  # Observing risk-seeking agent
â”œâ”€â”€ sess_5.psyexp               # Final self-decision session
â””â”€â”€ suzuki2016.pdf              # Reference paper

```

ğŸ§  Goal: Track shifts in participant risk-taking after observing othersâ€™ decisions

---

## â–¶ï¸ How to Run

### Option A â€” Run in Coder (Recommended)
1. Install PsychoPy (â‰¥ v2023.x)
2. Open `.psyexp` file in Builder  
3. Press **â–¶ Run**

Each session logs:
```

data/
â”œâ”€â”€ subjectID_date.csv   # Choice, RT & reward logs

```

---

## ğŸ” What is logged?

| Measure | Barakchian | Suzuki |
|--------|:---------:|:------:|
| Choices | âœ… | âœ… |
| Reaction Times | âœ… | âœ… |
| Reward Outcomes | âœ… | âœ… |
| Feedback Type | âœ… | âŒ |
| Social Context | âŒ | âœ… |

These logs are suitable for further **RL model fitting** (e.g., Q-learning & OL models).

---

## ğŸ“Œ References

- Barakchian, Z. et al. (2022). *Implicit Counterfactual Effect in Partial Feedback Reinforcement Learning: Behavioral and Modeling Approach*. Frontiers in Neuroscience.  
- Suzuki, S. et al. (2016). *Behavioral Contagion During Learning About Another Agentâ€™s Risk-Preferences*. PNAS.




